{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading libraries\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path =  'yds_train2018.csv'\n",
    "train_df = pd.read_csv(train_data_path) #loading train data\n",
    "\n",
    "test_data_path =  'yds_test2018.csv'\n",
    "test_df = pd.read_csv(test_data_path) # loading test data\n",
    "\n",
    "temp = test_df.groupby('Country').agg('size').reset_index() #\n",
    "temp.columns = ['Country', 'No_of_Months']\n",
    "forecast_period = temp['No_of_Months'].max()*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "As the train data in on Merchant level, I doppped 'Merchant_ID' and rolled up the data to Product level by summing up the Sales values.\n",
    "'''\n",
    "train_df.drop('Merchant_ID', axis=1, inplace=True)\n",
    "train_df = train_df.groupby(['Country', 'Year', 'Month','Week', 'Product_ID'])\n",
    "train_df = train_df.agg('sum')['Sales'].reset_index()\n",
    "train_df.columns = ['Country', 'Year', 'Month','Week', 'Product_ID', 'Monthly_Productwise_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To include time dimension in the train dataset, I added 'Day' (day of the Year) feature. Then formatted the string to datetime.\n",
    "'''\n",
    "train_df['Day'] = ((train_df['Week'] - 1)*7)+1\n",
    "train_df['Date'] = train_df['Year'].astype(str) + '/' + train_df['Month'].astype(str) + '/' + train_df['Day'].astype(str)\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date'], format = '%Y/%m/%j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>4335975.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2</td>\n",
       "      <td>395846.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>9753975.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2</td>\n",
       "      <td>1449848.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-15</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>10309950.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Country  Product_ID        Sales\n",
       "Date                                          \n",
       "2013-01-01  Argentina           1   4335975.00\n",
       "2013-01-01  Argentina           2    395846.92\n",
       "2013-01-08  Argentina           1   9753975.00\n",
       "2013-01-08  Argentina           2   1449848.96\n",
       "2013-01-15  Argentina           1  10309950.00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The information of Year, Month and Week are captured in  Date feature. Hence I droppped it. Added Date feature as the Index of dataframe.\n",
    "'''\n",
    "train_df.drop('Year', axis=1, inplace=True)\n",
    "train_df.drop('Month', axis=1, inplace=True)\n",
    "train_df.drop('Week', axis=1, inplace=True)\n",
    "train_df.drop('Day', axis=1, inplace=True)\n",
    "\n",
    "train_df.index = train_df['Date']\n",
    "train_df.drop('Date', axis=1, inplace=True)\n",
    "train_df.columns = ['Country', 'Product_ID', 'Sales']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To bring the data down to datetime, the dataset was groupped with Country, Product_ID and stored each group in 'dataframes' list. \n",
    "ARIMA can be applied at this level (to each group seperately).\n",
    "'''\n",
    "temp = train_df.groupby(['Country','Product_ID'])\n",
    "df_names = []\n",
    "dataframes = []\n",
    "for name, group in temp:\n",
    "    df_names.append('train_'+name[0]+'_'+str(name[1]))\n",
    "    dataframes.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>4335975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>9753975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-15</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>10309950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-22</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>7484400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-29</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>2461725.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Country  Product_ID       Sales\n",
       "Date                                         \n",
       "2013-01-01  Argentina           1   4335975.0\n",
       "2013-01-08  Argentina           1   9753975.0\n",
       "2013-01-15  Argentina           1  10309950.0\n",
       "2013-01-22  Argentina           1   7484400.0\n",
       "2013-01-29  Argentina           1   2461725.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = d = q = range(0, 3)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 7) for x in list(itertools.product(p, d, q))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test_df.groupby('Country').agg('size').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getForecast(sales_ts, temp):\n",
    "    \n",
    "    best_aic = np.inf\n",
    "    best_pdq = None\n",
    "    best_seasonal_pdq = None \n",
    "    temp_model = None\n",
    "\n",
    "    for param in pdq:\n",
    "        print (param)\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "            try:\n",
    "                temp_model = sm.tsa.statespace.SARIMAX(sales_ts,\n",
    "                                             order = param,\n",
    "                                             seasonal_order = param_seasonal,\n",
    "                                             enforce_stationarity=True,\n",
    "                                             enforce_invertibility=True)\n",
    "                results = temp_model.fit()\n",
    "\n",
    "                if results.aic < best_aic:\n",
    "                    best_aic = results.aic\n",
    "                    best_pdq = param\n",
    "                    best_seasonal_pdq = param_seasonal\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    best_model = sm.tsa.statespace.SARIMAX(sales_ts,\n",
    "                                      order=best_pdq,\n",
    "                                      seasonal_order=best_seasonal_pdq,\n",
    "                                      enforce_stationarity=True,\n",
    "                                      enforce_invertibility=True)\n",
    "    best_results = best_model.fit()\n",
    "    \n",
    "    period = int(temp[temp['Country'] == country][0]*5)\n",
    "    pred_uc_99 = best_results.get_forecast(steps=period, alpha=0.01)\n",
    "    forecast = pred_uc_99.predicted_mean\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_Argentina_1\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "train_Argentina_2\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "train_Argentina_3\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "train_Belgium_2\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "train_Columbia_1\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "train_Columbia_2\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "train_Columbia_3\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "train_Denmark_2\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "train_England_4\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "train_England_5\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "train_Finland_4\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "forecast_dfs = []\n",
    "for i in range(len(dataframes)):\n",
    "    print (df_names[i])\n",
    "    sales_ts = dataframes[i]['Sales']\n",
    "    country = dataframes[i]['Country'].iloc[0]\n",
    "    forecast = getForecast(sales_ts, temp)\n",
    "    \n",
    "    period = int(temp[temp['Country'] == country][0]*5)\n",
    "    time_period = pd.date_range(start = dataframes[i].index[-1], periods=period+1, freq = '7D').values[1:]\n",
    "    df = pd.DataFrame()\n",
    "    df['Forecast'] = forecast\n",
    "    df['Country'] = dataframes[i]['Country'].iloc[0]\n",
    "    df['Product_ID'] = dataframes[i]['Product_ID'].iloc[0]\n",
    "    df.index = time_period\n",
    "    forecast_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Formatting every forecast dataframe according to Test Data. Added 'Month', 'Year' column. \n",
    "Since the forecast is on week level, I added weekly sales in every month to roll it up to Month level. \n",
    "'''\n",
    "for i in range(len(forecast_dfs)):\n",
    "    forecast_df = forecast_dfs[i]\n",
    "    forecast_df['Month'] = forecast_df.index.month\n",
    "    forecast_df['Year'] = forecast_df.index.year\n",
    "    temp = forecast_df.groupby('Month').agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Joining all monthly forecast dataframes at country, product level into final dataframe('full_df') which can be merged with Test Data\n",
    "to get final results.\n",
    "'''\n",
    "full_df = forecast_dfs[0][['Forecast','Year', 'Month']].groupby(['Year','Month']).agg('sum').reset_index()\n",
    "full_df['Country'] = forecast_dfs[0].iloc[0]['Country']\n",
    "full_df['Product_ID'] = forecast_dfs[0].iloc[0]['Product_ID']\n",
    "for i in range(1,len(forecast_dfs)):\n",
    "    k = forecast_dfs[i][['Forecast','Year', 'Month']].groupby(['Year','Month']).agg('sum').reset_index()\n",
    "    k['Country'] = forecast_dfs[i].iloc[i]['Country']\n",
    "    k['Product_ID'] = forecast_dfs[i].iloc[i]['Product_ID']\n",
    "    full_df = pd.concat([full_df, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast = full_df['Forecast']\n",
    "# forecast[forecast<0] = 0\n",
    "# full_df['Forecast'] = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79073</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79074</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79075</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79076</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79077</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    S_No  Year  Month  Product_ID    Country  Sales\n",
       "0  79073  2016      4           1  Argentina    NaN\n",
       "1  79074  2016      5           1  Argentina    NaN\n",
       "2  79075  2016      6           1  Argentina    NaN\n",
       "3  79076  2016      7           1  Argentina    NaN\n",
       "4  79077  2016      8           1  Argentina    NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_path =  'yds_test2018.csv'\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(test_df, full_df, on=['Year', 'Month','Product_ID', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79073</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.059222e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79074</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.494083e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79075</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.935086e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79076</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.593549e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79077</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.713509e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    S_No  Year  Month  Product_ID    Country  Sales      Forecast\n",
       "0  79073  2016      4           1  Argentina    NaN  1.059222e+07\n",
       "1  79074  2016      5           1  Argentina    NaN  7.494083e+06\n",
       "2  79075  2016      6           1  Argentina    NaN  7.935086e+06\n",
       "3  79076  2016      7           1  Argentina    NaN  5.593549e+06\n",
       "4  79077  2016      8           1  Argentina    NaN  5.713509e+06"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = final_df['Forecast']\n",
    "final_df.drop('Forecast', axis=1, inplace=True)\n",
    "forecast[forecast<0] = min(forecast)\n",
    "final_df['Sales'] = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dict = {'Argentina':'0', 'Belgium':'1', 'Columbia':'2', 'Denmark':'3', 'Finland':'4', 'England':'5'}\n",
    "inverse_country_dict = { 0:'Argentina', 1:'Belgium', 2:'Columbia', 3:'Denmark', 4:'Finland', 5:'England'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n",
      "No of null values in Expense columns: 52\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data\\yds_train2018.csv')\n",
    "\n",
    "train_df.drop('Week', axis = 1, inplace=True)\n",
    "train_df.drop('Merchant_ID', axis=1, inplace=True)\n",
    "train_df.drop('S_No', axis=1, inplace=True)\n",
    "\n",
    "temp = train_df.groupby(['Country', 'Year', 'Month', 'Product_ID'])\n",
    "temp = temp.agg('sum')['Sales'].reset_index()\n",
    "temp.columns = ['Country', 'Year', 'Month', 'Product_ID', 'Monthly_Productwise_sales']\n",
    "train_df = temp.copy()\n",
    "\n",
    "expense_df = pd.read_csv('data\\promotional_expense.csv')\n",
    "expense_df.columns = ['Year', 'Month', 'Country', 'Product_ID', 'Expense']\n",
    "expense_df.head()\n",
    "\n",
    "train_df = pd.merge(train_df, expense_df, on=['Year', 'Month', 'Country', 'Product_ID'], how='left')\n",
    "train_df['Country'] = train_df['Country'].apply(lambda x: country_dict[x])\n",
    "train_df.columns = ['Country', 'Year', 'Month', 'Product_ID', 'Sales', 'Expense']\n",
    "print (train_df.shape[0])\n",
    "print ('No of null values in Expense columns: '+ str(len(train_df) - train_df['Expense'].count()))\n",
    "train_df['Expense'] = train_df['Expense'].fillna(train_df['Expense'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(l):\n",
    "    x = ''\n",
    "    l.sort()\n",
    "    for y in l:\n",
    "        x = x+''+str(y)\n",
    "    return x\n",
    "\n",
    "def read_date_from_holiday(df):\n",
    "    year = []\n",
    "    month = []\n",
    "    for i in range(df.shape[0]):\n",
    "        l = df['Date'].iloc[i].split(',')\n",
    "        year.append(l[0].strip())\n",
    "        month.append(l[1].strip())\n",
    "    return year, month\n",
    "\n",
    "def sMAPE(preds, y):\n",
    "    score = np.sum( np.abs(preds - y)/ (np.abs(y)+np.abs(preds))*0.5 ) * 100/len(preds)\n",
    "    return 'sMAPE', score\n",
    "\n",
    "def get_count_yearwise(df, var):\n",
    "    temp = df.groupby(['Country','Year', var]).agg('size').reset_index()\n",
    "    temp.columns = ['Country','Year', var, var+'_country_count']\n",
    "    df = df.merge(temp, on=['Country','Year', var], how='left')\n",
    "    return df\n",
    "\n",
    "def get_count_monthwise(df, var):\n",
    "    temp = df.groupby(['Country','Month', var]).agg('size').reset_index()\n",
    "    temp.columns = ['Country','Month', var, var+'_month_count']\n",
    "    df = df.merge(temp, on=['Country','Month', var], how='left')\n",
    "    return df\n",
    "\n",
    "def get_expense_stats(df, var):\n",
    "    mean = {}\n",
    "    min = {}\n",
    "    max = {}\n",
    "    temp = df.groupby(var)\n",
    "    print (var)\n",
    "    for name, group in temp:\n",
    "        mean[name] = np.mean(group['Expense'])\n",
    "        min[name] = np.min(group['Expense'])\n",
    "        max[name] = np.max(group['Expense'])\n",
    "    return (mean, min, max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Holiday Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data = pd.read_excel('data\\holidays.xlsx')\n",
    "holiday_data['Country'] = holiday_data['Country'].apply(lambda x: country_dict[x])\n",
    "\n",
    "year, month = read_date_from_holiday(holiday_data)\n",
    "holiday_data['Year'] = year\n",
    "holiday_data['Month'] = month\n",
    "\n",
    "holiday_data.drop('Date', axis=1, inplace=True)\n",
    "holiday_data['Year'] = holiday_data['Year'].astype(int)\n",
    "holiday_data['Month'] = holiday_data['Month'].astype(int)\n",
    "holiday_data['Holiday'] = holiday_data['Holiday'].astype(str)\n",
    "holiday_data.head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl = LabelEncoder()\n",
    "holiday_data['Holiday'] = lbl.fit_transform(holiday_data['Holiday'])\n",
    "\n",
    "holiday_temp = holiday_data.groupby(['Country', 'Year', 'Month', 'Holiday']).agg('size').reset_index()\n",
    "holiday_temp.columns = ['Country', 'Year', 'Month', 'Holiday', 'Holiday_Period']\n",
    "\n",
    "unique_holidays_monthwise = holiday_temp.groupby(['Country', 'Year', 'Month']).agg('size').reset_index()\n",
    "\n",
    "\n",
    "check = holiday_temp.groupby(['Country', 'Year', 'Month'])\n",
    "\n",
    "concatinated_holidays = []\n",
    "for name, group in check:\n",
    "    concatinated_holidays.append(concat(group['Holiday'].values))\n",
    "\n",
    "unique_holidays_monthwise['Holiday'] = concatinated_holidays\n",
    "\n",
    "unique_holidays_monthwise.columns = ['Country', 'Year', 'Month', 'No_of_unique_festivals', 'Holiday']\n",
    "holiday_monthwise = holiday_data.groupby(['Country', 'Year', 'Month']).agg('size').reset_index()\n",
    "holiday_monthwise.columns = ['Country', 'Year', 'Month', 'Holiday_count_every_month']\n",
    "\n",
    "modified_holiday_data = pd.merge(unique_holidays_monthwise, holiday_monthwise, on=['Country', 'Year', 'Month'])\n",
    "train_df = pd.merge(train_df, modified_holiday_data, on=['Year', 'Month', 'Country'], how='left')\n",
    "train_df = train_df.drop_duplicates().reset_index()\n",
    "train_df.drop('index', axis=1, inplace=True)\n",
    "\n",
    "train_df['No_of_unique_festivals'] = train_df['No_of_unique_festivals'].fillna(0)\n",
    "train_df['Holiday'] = train_df['Holiday'].fillna('999')\n",
    "train_df['Holiday_count_every_month'] = train_df['Holiday_count_every_month'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Expense</th>\n",
       "      <th>No_of_unique_festivals</th>\n",
       "      <th>Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34346025.00</td>\n",
       "      <td>14749.307</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2751851.48</td>\n",
       "      <td>1329.374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32005575.00</td>\n",
       "      <td>12187.566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2804313.12</td>\n",
       "      <td>1315.006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32530050.00</td>\n",
       "      <td>13076.579</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Year  Month  Product_ID        Sales    Expense  \\\n",
       "0        0  2013      1           1  34346025.00  14749.307   \n",
       "1        0  2013      1           2   2751851.48   1329.374   \n",
       "2        0  2013      2           1  32005575.00  12187.566   \n",
       "3        0  2013      2           2   2804313.12   1315.006   \n",
       "4        0  2013      3           1  32530050.00  13076.579   \n",
       "\n",
       "   No_of_unique_festivals  Holiday  \n",
       "0                     1.0        0  \n",
       "1                     1.0        0  \n",
       "2                     1.0        2  \n",
       "3                     1.0        2  \n",
       "4                     3.0       53  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data\\yds_test2018.csv')\n",
    "test_df.to_csv('data\\submission0.csv')\n",
    "\n",
    "test_df.drop('S_No', axis=1, inplace=True)\n",
    "test_df.drop('Sales', axis=1, inplace=True)\n",
    "test_df = pd.merge(test_df, expense_df, on=['Year', 'Month', 'Country', 'Product_ID'], how='left')\n",
    "test_df['Country'] = test_df['Country'].apply(lambda x: country_dict[x])\n",
    "\n",
    "test_df = pd.merge(test_df, modified_holiday_data, on=['Year', 'Month', 'Country'], how='left')\n",
    "test_df = test_df.drop_duplicates().reset_index()\n",
    "test_df.drop('index', axis=1, inplace=True)\n",
    "\n",
    "test_df['No_of_unique_festivals'] = test_df['No_of_unique_festivals'].fillna(0)\n",
    "test_df['Holiday'] = test_df['Holiday'].fillna('999')\n",
    "test_df['Holiday_count_every_month'] = test_df['Holiday_count_every_month'].fillna(0)\n",
    "\n",
    "test_df = test_df[['Country','Year', 'Month', 'Product_ID', 'Expense', 'No_of_unique_festivals', 'Holiday', 'Holiday_count_every_month']]\n",
    "\n",
    "train_df['Country'] = train_df['Country'].astype(int)\n",
    "train_df['Holiday'] = train_df['Holiday'].astype(int)\n",
    "\n",
    "test_df['Country'] = test_df['Country'].astype(int)\n",
    "test_df['Holiday'] = test_df['Holiday'].astype(int)\n",
    "\n",
    "test_df['Expense'] = test_df['Expense'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Holiday'] = lbl.fit_transform(train_df['Holiday'])\n",
    "test_df['Holiday'] = lbl.fit_transform(test_df['Holiday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop('Holiday_count_every_month', axis=1, inplace=True)\n",
    "train_df.drop('Holiday_count_every_month', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Expense</th>\n",
       "      <th>No_of_unique_festivals</th>\n",
       "      <th>Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8214.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10777.878</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10320.673</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7377.587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9805.705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Year  Month  Product_ID    Expense  No_of_unique_festivals  \\\n",
       "0        0  2016      4           1   8214.875                     1.0   \n",
       "1        0  2016      5           1  10777.878                     2.0   \n",
       "2        0  2016      6           1  10320.673                     2.0   \n",
       "3        0  2016      7           1   7377.587                     1.0   \n",
       "4        0  2016      8           1   9805.705                     1.0   \n",
       "\n",
       "   Holiday  \n",
       "0       11  \n",
       "1       26  \n",
       "2       24  \n",
       "3        8  \n",
       "4        7  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_categories = ['Product_ID']\n",
    "for x in count_categories:\n",
    "    train_df = get_count_yearwise(train_df, x)\n",
    "    train_df = get_count_monthwise(train_df, x)\n",
    "    test_df = get_count_monthwise(test_df, x)\n",
    "    test_df = get_count_yearwise(test_df, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "Product_ID\n",
      "Country\n",
      "Month\n",
      "Product_ID\n",
      "Country\n"
     ]
    }
   ],
   "source": [
    "categories = ['Month', 'Product_ID', 'Country']\n",
    "\n",
    "for x in categories:\n",
    "    mean, min_, max_ = get_expense_stats(train_df, x)\n",
    "    train_df[x+'_mean'], train_df[x+'_min'] , train_df[x+'_max']  = train_df[x].apply(lambda x: mean[x]), train_df[x].apply(lambda x: min_[x]), train_df[x].apply(lambda x: max_[x])\n",
    "\n",
    "for x in categories:\n",
    "    mean, min_, max_ = get_expense_stats(test_df, x)    \n",
    "    test_df[x+'_mean'], test_df[x+'_min'] , test_df[x+'_max']  = test_df[x].apply(lambda x: mean[x]), test_df[x].apply(lambda x: min_[x]), test_df[x].apply(lambda x: max_[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output = train_df['Sales']\n",
    "#train_df.drop('Sales', axis=1, inplace=True)\n",
    "train_X, test_X, train_y, test_y = train_test_split(train_df, Output, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 18)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sMAPE', 11.067373237614683)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "model.fit(train_X, train_y)\n",
    "val_pred = model.predict(test_X)\n",
    "\n",
    "sMAPE(val_pred, test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sMAPE', 4.138804128817378)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(train_df, Output, test_size=0.3, random_state=123)\n",
    "model_1 = xgb.XGBRegressor(n_estimators= 50,\n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 6,\n",
    "                           colsample_bylevel = 0.6,\n",
    "                           feval = sMAPE,\n",
    "                           maximize=False\n",
    "                          )\n",
    "model_1.fit(train_X.values, train_y.values)\n",
    "test_pred_1 = model_1.predict(test_X.values)\n",
    "sMAPE(test_pred_1, test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sMAPE', 3.9222568782812703)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(train_df, Output, test_size=0.3, random_state=123)\n",
    "model_2 = xgb.XGBRegressor(n_estimators= 50,\n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 6,\n",
    "                           colsample_bylevel = 0.5,\n",
    "                           feval = sMAPE,\n",
    "                           maximize=False\n",
    "                          )\n",
    "model_2.fit(train_X.values, train_y.values, eval_set=[(test_X.values, test_y.values)], verbose=0)\n",
    "test_pred_2 = model_2.predict(test_X.values)\n",
    "sMAPE(test_pred_2, test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('submissions/submission0.csv')\n",
    "final_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "final_df.drop('Sales', axis=1, inplace=True)\n",
    "\n",
    "pred6 = model_1.predict(test_df.values)*0.3 + model_2.predict(test_df.values) * 0.7\n",
    "pred6 = np.abs(pred6)\n",
    "\n",
    "final_df['Sales'] = pred6\n",
    "\n",
    "final_df.to_csv('submissions/submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging  ARIMA, 2XGBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('submissions/submission2.csv')\n",
    "df2 = pd.read_csv('submissions/submission3.csv')\n",
    "\n",
    "final_pred = df1['Sales']*0.5 + df2['Sales']*0.5\n",
    "\n",
    "final_df = pd.read_csv('submissions/submission0.csv')\n",
    "final_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "final_df.drop('Sales', axis=1, inplace=True)\n",
    "final_df['Sales'] =  final_pred\n",
    "\n",
    "final_df.to_csv('submissions/shariq_final_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
